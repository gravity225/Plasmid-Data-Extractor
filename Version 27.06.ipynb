{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1301589e",
   "metadata": {},
   "source": [
    "# Current\n",
    "\n",
    "problemo gelöst. jetzt nur noch all data in csv umschreiben wäre cool!\n",
    "\n",
    "-> gespräch mit niko. nach plasmid id filtern. \n",
    "\n",
    "\n",
    "das war eine erfolgreiche woche:\n",
    "\n",
    "## achivements:\n",
    "erfolgreich dictionnaries erstellt \\\n",
    "erfolgreich dokument umgebaut \\\n",
    "erfolgreich id extrahiert und in dictionaries eingebaut\\\n",
    "erfolgreich csv datei erstellt\\\n",
    "erfolgreich text dokument erstellt damit es übersichtlicher ist.\n",
    "\n",
    "## weiter:\n",
    "was genau muss ich noch extrahieren siehe labkey\\\n",
    "kann man daten (andere dateifomate) im csv einpflegen welche ich in labkey hinterlegen kann?\\\n",
    "boolian schlaufe für resistenzen basteln\n",
    "\n",
    "Achtung! Hier der richtige Link zum KIT:\\\n",
    "https://www.addgene.org/kits/hahn-root-human-kinases/#kit-contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb6460c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ss/rflvbtfd7j99nj3s9gb1xf5w0031ww/T/ipykernel_26797/3336403303.py:89: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  gesuchtes_wort_element1 = link_soup.find(text=re.compile(gesuchtes_wort1))\n",
      "/var/folders/ss/rflvbtfd7j99nj3s9gb1xf5w0031ww/T/ipykernel_26797/3336403303.py:103: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  gesuchtes_wort_element2 = link_soup.find(text=re.compile(gesuchtes_wort2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'addgene_id_0': '78250', 'Vector backbone': 'pTol2pA2', 'Vector type': 'Zebrafish motor neuron expression', 'Bacterial Resistance': 'Ampicillin, 100 μg/mL', 'Growth Strain': 'DH5alpha'}, {'addgene_id_0': '78251', 'Vector backbone': 'pTol2pA2', 'Vector type': 'Zebrafish motor neuron inducible expression', 'Bacterial Resistance': 'Ampicillin, 100 μg/mL', 'Growth Strain': 'DH5alpha'}, {'addgene_id_0': '75023', 'Vector backbone': 'pDONRP2R-P3', 'Vector type': \"5' entry vector for Multisite Gateway Three Fragment vector construction kit (Invitrogen)\", 'Bacterial Resistance': 'Kanamycin, 50 μg/mL', 'Growth Strain': 'DH5alpha'}, {'addgene_id_0': '75024', 'Vector backbone': 'pDONRP2R-P3', 'Vector type': \"5' entry vector for Multisite Gateway Three Fragment vector construction kit (Invitrogen)\", 'Bacterial Resistance': 'Kanamycin, 50 μg/mL', 'Growth Strain': 'DH5alpha'}, {'addgene_id_0': '75025', 'Vector backbone': 'pDONRP2R-P3', 'Vector type': \"5' entry vector for Multisite Gateway Three Fragment vector construction kit (Invitrogen)\", 'Bacterial Resistance': 'Kanamycin, 50 μg/mL', 'Growth Strain': 'DH5alpha'}, {'addgene_id_0': '75148', 'Vector backbone': 'pDONR221', 'Vector type': 'Middle entry vector for Multisite Gateway Three Fragment vector construction kit (Invitrogen)', 'Bacterial Resistance': 'Kanamycin, 50 μg/mL', 'Growth Strain': 'DH5alpha'}, {'addgene_id_0': '75149', 'Vector backbone': 'pDONR221', 'Vector type': 'Middle entry vector for Multisite Gateway Three Fragment vector construction kit (Invitrogen)', 'Bacterial Resistance': 'Kanamycin, 50 μg/mL', 'Growth Strain': 'DH5alpha'}, {'addgene_id_0': '75153', 'Vector backbone': 'pDONR221', 'Vector type': 'Middle entry vector for Multisite Gateway Three Fragment vector construction kit (Invitrogen)', 'Bacterial Resistance': 'Kanamycin, 50 μg/mL', 'Growth Strain': 'DH5alpha'}, {'addgene_id_0': '75154', 'Vector backbone': 'pDONR221', 'Vector type': 'Middle entry vector for Multisite Gateway Three Fragment vector construction kit (Invitrogen)', 'Bacterial Resistance': 'Kanamycin, 50 μg/mL', 'Growth Strain': 'DH5alpha'}, {'addgene_id_0': '75155', 'Vector backbone': 'pDONR221', 'Vector type': 'Middle entry vector for Multisite Gateway Three Fragment vector construction kit (Invitrogen)', 'Bacterial Resistance': 'Kanamycin, 50 μg/mL', 'Growth Strain': 'DH5alpha'}, {'addgene_id_0': '75156', 'Vector backbone': 'pDONR221', 'Vector type': 'Middle entry vector for Multisite Gateway Three Fragment vector construction kit (Invitrogen)', 'Bacterial Resistance': 'Kanamycin, 50 μg/mL', 'Growth Strain': 'DH5alpha'}, {'addgene_id_0': '75158', 'Vector backbone': 'pDONR221', 'Vector type': 'Middle entry vector for Multisite Gateway Three Fragment vector construction kit (Invitrogen)', 'Bacterial Resistance': 'Kanamycin, 50 μg/mL', 'Growth Strain': 'DH5alpha'}, {'addgene_id_0': '75174', 'Vector backbone': 'pDONRP4P1R', 'Vector type': 'Three prime entry vector for Multisite Gateway Three Fragment vector construction kit (Invitrogen)', 'Bacterial Resistance': 'Kanamycin, 50 μg/mL', 'Growth Strain': 'DH5alpha'}, {'addgene_id_0': '75175', 'Vector backbone': 'pDONRP4P1R', 'Vector type': 'Three prime entry vector for Multisite Gateway Three Fragment vector construction kit (Invitrogen)', 'Bacterial Resistance': 'Kanamycin, 50 μg/mL', 'Growth Strain': 'DH5alpha'}, {'addgene_id_0': '75176', 'Vector backbone': 'pDONRP4P1R', 'Vector type': 'Three prime entry vector for Multisite Gateway Three Fragment vector construction kit (Invitrogen)', 'Bacterial Resistance': 'Kanamycin, 50 μg/mL', 'Growth Strain': 'DH5alpha'}, {'addgene_id_0': '75177', 'Vector backbone': 'pDONRP4P1R', 'Vector type': 'Three prime entry vector for Multisite Gateway Three Fragment vector construction kit (Invitrogen)', 'Bacterial Resistance': 'Kanamycin, 50 μg/mL', 'Growth Strain': 'DH5alpha'}, {'addgene_id_0': '75179', 'Vector backbone': 'pDONRP4P1R', 'Vector type': 'Three prime entry vector for Multisite Gateway Three Fragment vector construction kit (Invitrogen)', 'Bacterial Resistance': 'Kanamycin, 50 μg/mL', 'Growth Strain': 'DH5alpha'}, {'addgene_id_0': '75180', 'Vector backbone': 'pDONRP4P1R', 'Vector type': 'Three prime entry vector for Multisite Gateway Three Fragment vector construction kit (Invitrogen)', 'Bacterial Resistance': 'Kanamycin, 50 μg/mL', 'Growth Strain': 'DH5alpha'}, {'addgene_id_0': '74632', 'Vector backbone': 'pDONRP2R-P3', 'Vector type': \"5' entry vector for Multisite Gateway Three Fragment vector construction kit(Invitrogen)\", 'Bacterial Resistance': 'Kanamycin, 50 μg/mL', 'Growth Strain': 'DH5alpha'}]\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "#datei von oben am bearbeiten!!! nicht mehr nach html titel extrahieren sondern nach bestimmten wörtern da ich NUR bestimmte informationen haben will!\n",
    "\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import re \n",
    "#reguläres Ausdrucksobjekt, das das gesuchte Wort repräsentiert.\n",
    "\n",
    "#csv öffnen\n",
    "with open('daten.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "\n",
    "    #link öffnen\n",
    "    url = 'https://www.addgene.org/kits/cole-tol2-neuro-toolbox/#kit-contents'\n",
    "\n",
    "\n",
    "\n",
    "    # Die Webseite abrufen\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "\n",
    "    #suchbegriffe definieren nach was genau will ich filtern?\n",
    "    header = ['addgene_id_0']\n",
    "    list = [\"Vector backbone\", \"Vector type\"]\n",
    "    list_klammer = [\"Bacterial Resistance\", \"Growth Strain\"]\n",
    "    all_data = []\n",
    "\n",
    "\n",
    "\n",
    "#csv füllen\n",
    "    #spaltenueberschrift definieren\n",
    "    fieldnames = header + list + list_klammer\n",
    "    \n",
    "    # Erstelle den CSV-Schreiber\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Schreibe die Spaltenüberschriften in die CSV-Datei\n",
    "    writer.writeheader()\n",
    "\n",
    "\n",
    "\n",
    "#informationen scrapen    \n",
    "    \n",
    "    \n",
    "    # Die Tabelle finden, die die Kit-Inhalte enthält\n",
    "    table = soup.find('table', class_='table')\n",
    "\n",
    "    if table:\n",
    "        # Die Tabellenzeilen finden\n",
    "        rows = table.find_all('tr')\n",
    "        \n",
    "        \n",
    "        # Die Daten für jede Zeile ausdrucken\n",
    "        for row in rows:\n",
    "            \n",
    "            #für jeden Datensatz wird ein dic erstellt\n",
    "            dic = {}\n",
    "            \n",
    "            columns = row.find_all('td')\n",
    "            if columns:\n",
    "                # Die URL in der ersten Spalte (falls vorhanden) finden\n",
    "                url_column = columns[1].find('a')\n",
    "                \n",
    "                \n",
    "                if url_column:\n",
    "                    # Die URL extrahieren und den Link aufrufen\n",
    "                    link_url = urljoin(url, url_column['href'])\n",
    "                    link_response = requests.get(link_url)\n",
    "                    link_soup = BeautifulSoup(link_response.text, 'html.parser')\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    # Suche nach dem plasmid-id in HTML-Code der Webseite\n",
    "                    id = link_soup.find('span', id='addgene-item-id')\n",
    "                    dic['addgene_id_0'] = id.text\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    #erste liste iterieren OHNE sonderzeichen\n",
    "                    for gesuchtes_wort1 in list:\n",
    "                        #wort finden\n",
    "                        gesuchtes_wort_element1 = link_soup.find(text=re.compile(gesuchtes_wort1))\n",
    "                        \n",
    "                        if gesuchtes_wort_element1:\n",
    "                            #nächst grösseres element finden\n",
    "                            parent1 = gesuchtes_wort_element1.find_parent('li', class_='field')\n",
    "                            #grösseres element text extrahiren und splitten nach gewünschten daten\n",
    "                            information_list_1 = parent1.get_text(strip=True).split(gesuchtes_wort1)\n",
    "                            #dictionary zuweisen\n",
    "                            dic[gesuchtes_wort1] = information_list_1[1]\n",
    "\n",
    "                    \n",
    "                    #zweite liste iterieren MIT sonderzeichen\n",
    "                    for gesuchtes_wort2 in list_klammer:\n",
    "                        \n",
    "                        gesuchtes_wort_element2 = link_soup.find(text=re.compile(gesuchtes_wort2))\n",
    "                        \n",
    "                        if gesuchtes_wort_element2:\n",
    "                            parent2 = gesuchtes_wort_element2.find_parent('li', class_='field')\n",
    "                            \n",
    "                            information_list_klammer = parent2.get_text(strip=True).split(')')\n",
    "                            dic[gesuchtes_wort2] = information_list_klammer[1]\n",
    "                    \n",
    "                    \n",
    "                        else:\n",
    "                            print(\"nicht gefunden :/\")\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                all_data.append(dic)\n",
    "    \n",
    "    \n",
    "    for plasmid in all_data:\n",
    "        writer.writerow(plasmid)\n",
    "    \n",
    "    \n",
    "            \n",
    "print(all_data) \n",
    "\n",
    "print(len(all_data))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3380c116",
   "metadata": {},
   "source": [
    "# text datei\n",
    "\n",
    "das csv format ist mir ein bischen unübersichtlich\n",
    "ich schreibe das ganze einmal in eine text datei um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f33b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "min_width = 5\n",
    "max_width = 100\n",
    "\n",
    "#berechnet die breite jeder spalte und stellt sicher dass sie innerhalb der minimalen und maximalen breite liegen\n",
    "widths = {field: min(max(len(field), max(len(str(row[field])) for row in all_data) + 2), max_width) for field in fieldnames}\n",
    "widths = {field: max(width, min_width) for field, width in widths.items()}\n",
    "\n",
    "with open('addgenedata.txt', mode='w', encoding='utf-8') as file:\n",
    "    header = ''\n",
    "    for field in fieldnames:\n",
    "        header += f\"{field:<{widths[field]}} \"\n",
    "    file.write(header.rstrip() + '\\n')\n",
    "    \n",
    "    # Über die Liste von Dictionaries iterieren und jedes Dictionary schreiben\n",
    "    for row in all_data:\n",
    "        line = ''\n",
    "        for field in fieldnames:\n",
    "            line += f\"{row[field]:<{widths[field]}} \"\n",
    "        file.write(line.rstrip() + '\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labkey-plasmid-importer",
   "language": "python",
   "name": "labkey-plasmid-importer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
